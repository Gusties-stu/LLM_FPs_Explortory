{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract The Numerical Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas\n",
    "\n",
    "with open(\"Answers.json\", \"r\") as file:\n",
    "    overall_data = json.load(file)\n",
    "\n",
    "df = pandas.DataFrame(\n",
    "    list(overall_data.items()), columns=[\"Fermi Question\", \"Dictionary\"]\n",
    ")\n",
    "\n",
    "with open(\"Units_Value.json\", \"r\") as file:\n",
    "    data_units = json.load(file)\n",
    "\n",
    "units_df = pandas.DataFrame(list(data_units), columns=[\"value\", \"unit\"])\n",
    "\n",
    "\n",
    "with open(\"Fermi_Classification.json\", \"r\") as file:\n",
    "    data_classification = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract the Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "openai_key = os.getenv(\"OPEN_AI_TOKEN\")\n",
    "openai.api_key = openai_key\n",
    "\n",
    "\n",
    "def extract_answer(question, answer, units):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Here is the fermi question given to the user to respond {question} and here is the response given {answer}.\n",
    "                     I want you to extract the answer from the response in the following units: {units}\"\"\",\n",
    "            }\n",
    "        ],\n",
    "        functions=[\n",
    "            {\n",
    "                \"name\": \"extract_fermi_question_answer\",\n",
    "                \"description\": f\"\"\" \n",
    "                                Extract the numerical answer of the fermi question from the response and transform to the following units if necessary. units: {units}.\n",
    "                                If the question was not answered return empty.\n",
    "                                If only a number was given then assume it is in the correct units.\n",
    "                                If the response given is in a fraction form transform to a decimal. \n",
    "                                    Example: 1/250,000,000 should return 4e-9\n",
    "                                \"\"\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"numerical_answer\": {\n",
    "                            \"type\": \"number\",\n",
    "                            \"description\": \"return the numerical answer to the fermi question or return empty if it was not answered\",\n",
    "                        }\n",
    "                    },\n",
    "                    \"required\": [\"numerical_answer\"],\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "    if response.choices[0].message.function_call:\n",
    "        data = response.choices[0].message.function_call.arguments\n",
    "        if data:\n",
    "            arguments = json.loads(data)\n",
    "        return arguments.get(\"numerical_answer\")\n",
    "\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How many golf balls put into the worlds oceans would it take to submerge all of the land on earth from the displaced water?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"Fermi Question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import replicate\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "replicate_token = os.getenv(\"REPLICATE_TOKEN\")\n",
    "\n",
    "replicate_client = replicate.Client(api_token=replicate_token)\n",
    "\n",
    "\n",
    "def generate_fermi_results(question, prompt, units):\n",
    "\n",
    "    template = f\"\"\"\n",
    "    You are a helpful assistant. I'd appreciate your assistance. \n",
    "    please avoid using scientific notation or large numbers words like millions or trillions to represent the answer in your answer\n",
    "    Use another form to replace it and please give your answer\n",
    "    In a value to the question in the last sentence, make sure \n",
    "    I'd like the final answer to the question to be a specific value, not part of a sentence!\n",
    "    Fractions should be 0. based not 1/ something\n",
    "    To clarify, just return the numerical answer in the following units: {units}\n",
    "    \"\"\"\n",
    "\n",
    "    output = replicate_client.run(\n",
    "        \"meta/meta-llama-3-70b-instruct\",\n",
    "        input={\n",
    "            \"prompt\": template + f\" Question: {question} \\nPrompt: {prompt}\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return (\"\".join(output),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_answer(question, prompt, units):\n",
    "    count = 0\n",
    "    num_ans = None\n",
    "    while count < 11 and not num_ans:\n",
    "        print(\"Found One\")\n",
    "        answer = generate_fermi_results(question, prompt, units)\n",
    "        num_ans = extract_answer(question, answer, units)\n",
    "        count += 1\n",
    "\n",
    "    return num_ans, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "Found One\n",
      "80\n",
      "90\n",
      "100\n",
      "Found One\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "Found One\n",
      "Found One\n",
      "Found One\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "Found One\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "Found One\n",
      "Found One\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "Found One\n",
      "Found One\n",
      "Found One\n",
      "530\n",
      "Found One\n",
      "540\n",
      "550\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "count_idx = 0\n",
    "more_than_one_standard = []\n",
    "more_than_one_specific = []\n",
    "for i in range(len(df)):\n",
    "    question = df.iloc[i][\"Fermi Question\"]\n",
    "    dictionary = df.iloc[i][\"Dictionary\"]\n",
    "    units = units_df.iloc[i][\"unit\"]\n",
    "\n",
    "    possible_new_row = [0, 0, 0]\n",
    "\n",
    "    num_ans_0 = extract_answer(question, dictionary[\"Level 0 Answer\"], units)\n",
    "    if num_ans_0 is None or num_ans_0 == \"\":\n",
    "        num_ans_0, count = numerical_answer(question, question, units)\n",
    "        possible_new_row[0] = count\n",
    "\n",
    "    num_ans_2 = extract_answer(question, dictionary[\"Level 2 Answer\"], units)\n",
    "    if num_ans_2 is None or num_ans_2 == \"\":\n",
    "        num_ans_2, count = numerical_answer(\n",
    "            question, dictionary[\"Level 2 Prompt\"], units\n",
    "        )\n",
    "        possible_new_row[1] = count\n",
    "\n",
    "    num_ans_4 = extract_answer(question, dictionary[\"Level 4 Answer\"], units)\n",
    "    if num_ans_4 is None or num_ans_4 == \"\":\n",
    "        num_ans_4, count = numerical_answer(\n",
    "            question, dictionary[\"Level 4 Prompt\"], units\n",
    "        )\n",
    "        possible_new_row[2] = count\n",
    "\n",
    "    for i in possible_new_row:\n",
    "        if i > 0:\n",
    "            if question in data_classification[\"specific\"]:\n",
    "                more_than_one_specific.append(possible_new_row)\n",
    "\n",
    "            else:\n",
    "                more_than_one_standard.append(possible_new_row)\n",
    "\n",
    "            break\n",
    "\n",
    "    rows.append([num_ans_0, num_ans_2, num_ans_4])\n",
    "\n",
    "    if count_idx % 10 == 0:\n",
    "        print(count_idx)\n",
    "\n",
    "    count_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number Of Questions that needed more than one hop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specific Questions BreakDown:\n",
      "\t # Questions Needed extra hop: Level 0: 2, Number of extra hops: 2\n",
      "\t # Questions Needed extra hop: Level 2: 2, Number of extra hops: 6\n",
      "\t # Questions Needed extra hop: Level 4: 1, Number of extra hops: 1\n",
      "Standard Questions BreakDown:\n",
      "\t # Questions Needed extra hop: Level 0: 2, Number of extra hops: 2\n",
      "\t # Questions Needed extra hop: Level 2: 0, Number of extra hops: 0\n",
      "\t # Questions Needed extra hop: Level 4: 1, Number of extra hops: 1\n"
     ]
    }
   ],
   "source": [
    "exp_level_0_count = 0\n",
    "exp_level_2_count = 0\n",
    "exp_level_4_count = 0\n",
    "\n",
    "exp_level_0 = 0\n",
    "exp_level_2 = 0\n",
    "exp_level_4 = 0\n",
    "\n",
    "for i in more_than_one_specific:\n",
    "    exp_level_0 += i[0]\n",
    "    exp_level_2 += i[1]\n",
    "    exp_level_4 += i[2]\n",
    "\n",
    "    exp_level_0_count = (\n",
    "        exp_level_0_count + 1 if i[0] > 0 else exp_level_0_count\n",
    "    )\n",
    "    exp_level_2_count = (\n",
    "        exp_level_2_count + 1 if i[1] > 0 else exp_level_2_count\n",
    "    )\n",
    "    exp_level_4_count = (\n",
    "        exp_level_4_count + 1 if i[2] > 0 else exp_level_4_count\n",
    "    )\n",
    "\n",
    "print(\"Specific Questions BreakDown:\")\n",
    "print(\n",
    "    f\"\\t # Questions Needed extra hop: Level 0: {exp_level_0_count}, Number of extra hops: {exp_level_0}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\t # Questions Needed extra hop: Level 2: {exp_level_2_count}, Number of extra hops: {exp_level_2}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\t # Questions Needed extra hop: Level 4: {exp_level_4_count}, Number of extra hops: {exp_level_4}\"\n",
    ")\n",
    "\n",
    "\n",
    "exp_level_0_count = 0\n",
    "exp_level_2_count = 0\n",
    "exp_level_4_count = 0\n",
    "\n",
    "exp_level_0 = 0\n",
    "exp_level_2 = 0\n",
    "exp_level_4 = 0\n",
    "\n",
    "for i in more_than_one_standard:\n",
    "    exp_level_0 += i[0]\n",
    "    exp_level_2 += i[1]\n",
    "    exp_level_4 += i[2]\n",
    "\n",
    "    exp_level_0_count = (\n",
    "        exp_level_0_count + 1 if i[0] > 0 else exp_level_0_count\n",
    "    )\n",
    "    exp_level_2_count = (\n",
    "        exp_level_2_count + 1 if i[1] > 0 else exp_level_2_count\n",
    "    )\n",
    "    exp_level_4_count = (\n",
    "        exp_level_4_count + 1 if i[2] > 0 else exp_level_4_count\n",
    "    )\n",
    "\n",
    "print(\"Standard Questions BreakDown:\")\n",
    "print(\n",
    "    f\"\\t # Questions Needed extra hop: Level 0: {exp_level_0_count}, Number of extra hops: {exp_level_0}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\t # Questions Needed extra hop: Level 2: {exp_level_2_count}, Number of extra hops: {exp_level_2}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\t # Questions Needed extra hop: Level 4: {exp_level_4_count}, Number of extra hops: {exp_level_4}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the FP Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "\n",
    "def calculate_fp_score(A_prime, A):\n",
    "    if A_prime == \"None\":\n",
    "        return \"Invalid Answer\"\n",
    "\n",
    "    try:\n",
    "        A_prime = float(A_prime)\n",
    "        A = float(A)\n",
    "        score = max(0, 1 - (1 / 3) * abs(math.log10(A_prime / A)))\n",
    "        return score\n",
    "    except ValueError:\n",
    "        return \"Invalid Answer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_scores = []\n",
    "fp_averages = []\n",
    "fp_std = []\n",
    "\n",
    "for idx, (a_0, a_2, a_4) in enumerate(rows):\n",
    "    value, unit = units_df.iloc[idx]\n",
    "\n",
    "    fp_score_0 = calculate_fp_score(a_0, value)\n",
    "    fp_score_2 = calculate_fp_score(a_2, value)\n",
    "    fp_score_4 = calculate_fp_score(a_4, value)\n",
    "\n",
    "    fp_row = [fp_score_0, fp_score_2, fp_score_4]\n",
    "\n",
    "    # Filter out None values\n",
    "    filtered_fp_row = [score for score in fp_row if score != \"Invalid Answer\"]\n",
    "\n",
    "    if filtered_fp_row:\n",
    "        std = np.std(filtered_fp_row)\n",
    "        average = np.mean(filtered_fp_row)\n",
    "    else:\n",
    "        std = None\n",
    "        average = None\n",
    "\n",
    "    fp_scores.append(fp_row)\n",
    "    fp_averages.append(average)\n",
    "    fp_std.append(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall and Level Average and Mean Results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_level_avg_std(level, fp_scores):\n",
    "\n",
    "    level = level // 2  # Since level will be 0, 2 or 4\n",
    "    filtered_fp_row = []\n",
    "\n",
    "    for row in fp_scores:\n",
    "        if row[level] != \"Invalid Answer\":\n",
    "            filtered_fp_row.append(row[level])\n",
    "\n",
    "    if filtered_fp_row:\n",
    "        std = np.std(filtered_fp_row)\n",
    "        average = np.mean(filtered_fp_row)\n",
    "    else:\n",
    "        std = None\n",
    "        average = None\n",
    "\n",
    "    return average, std\n",
    "\n",
    "\n",
    "def calculate_overall_avg_std(fp_scores):\n",
    "    filtered_fp_row = []\n",
    "\n",
    "    for row in fp_scores:\n",
    "        for score in row:\n",
    "            if score != \"Invalid Answer\":\n",
    "                filtered_fp_row.append(score)\n",
    "\n",
    "    if filtered_fp_row:\n",
    "        std = np.std(filtered_fp_row)\n",
    "        average = np.mean(filtered_fp_row)\n",
    "\n",
    "    else:\n",
    "        std = None\n",
    "        average = None\n",
    "\n",
    "    return average, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Results - Average: 0.49742570935920505, Standard Deviation: 0.38886527937471144\n",
      "Level 0 - Average: 0.4932278117818382, Standard Deviation: 0.38873077093727976\n",
      "Level 2 - Average: 0.50378139015012, Standard Deviation: 0.388095724845662\n",
      "Level 4 - Average: 0.4952416063487219, Standard Deviation: 0.3896846679298247\n"
     ]
    }
   ],
   "source": [
    "overall_average, overall_std = calculate_overall_avg_std(fp_scores)\n",
    "level_0_average, level_0_std = calculate_level_avg_std(0, fp_scores)\n",
    "level_2_average, level_2_std = calculate_level_avg_std(2, fp_scores)\n",
    "level_4_average, level_4_std = calculate_level_avg_std(4, fp_scores)\n",
    "\n",
    "\n",
    "print(\n",
    "    f\"Overall Results - Average: {overall_average}, Standard Deviation: {overall_std}\"\n",
    ")\n",
    "print(\n",
    "    f\"Level 0 - Average: {level_0_average}, Standard Deviation: {level_0_std}\"\n",
    ")\n",
    "print(\n",
    "    f\"Level 2 - Average: {level_2_average}, Standard Deviation: {level_2_std}\"\n",
    ")\n",
    "print(\n",
    "    f\"Level 4 - Average: {level_4_average}, Standard Deviation: {level_4_std}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to a JSON File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All FP Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to represent the JSON structure\n",
    "scores_dict = {}\n",
    "for idx, score_list in enumerate(fp_scores):\n",
    "    question = df.iloc[idx][\"Fermi Question\"]\n",
    "\n",
    "    scores_dict[question] = {\n",
    "        \"Level 0\": score_list[0],\n",
    "        \"Level 2\": score_list[1],\n",
    "        \"Level 4\": score_list[2],\n",
    "        \"Mean\": fp_averages[idx],\n",
    "        \"Standard Dev\": fp_std[idx],\n",
    "    }\n",
    "\n",
    "with open(\"fp_results.json\", \"w\") as file:\n",
    "    json.dump(scores_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Results JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Fermi_Classification.json\", \"r\") as file:\n",
    "    data_classification = json.load(file)\n",
    "\n",
    "with open(\"fp_results.json\", \"r\") as file:\n",
    "    fp_results_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_70b_results = {}\n",
    "\n",
    "for idx, (question, data) in enumerate(overall_data.items()):\n",
    "    type_question = (\n",
    "        \"specific\"\n",
    "        if question in data_classification[\"specific\"]\n",
    "        else \"standard\"\n",
    "    )\n",
    "    fp_question_results = fp_results_data[question]\n",
    "    extracted_row = rows[idx]\n",
    "\n",
    "    llama_70b_results[question] = {\n",
    "        \"Level 0\": {\n",
    "            \"Raw Answer\": data[\"Level 0 Answer\"],\n",
    "            \"Extracted Answer\": str(extracted_row[0]),\n",
    "            \"Level FP Score\": fp_question_results[\"Level 0\"],\n",
    "        },\n",
    "        \"Level 2\": {\n",
    "            \"Prompt\": data[\"Level 2 Prompt\"],\n",
    "            \"Raw Answer\": data[\"Level 2 Answer\"],\n",
    "            \"Extracted Answer\": str(extracted_row[1]),\n",
    "            \"Level FP Score\": fp_question_results[\"Level 2\"],\n",
    "        },\n",
    "        \"Level 4\": {\n",
    "            \"Prompt\": data[\"Level 4 Prompt\"],\n",
    "            \"Raw Answer\": data[\"Level 4 Answer\"],\n",
    "            \"Extracted Answer\": str(extracted_row[2]),\n",
    "            \"Level FP Score\": fp_question_results[\"Level 4\"],\n",
    "        },\n",
    "        \"Type\": type_question,\n",
    "        \"FP Score\": {\n",
    "            \"Mean\": fp_question_results[\"Mean\"],\n",
    "            \"Standard Dev\": fp_question_results[\"Standard Dev\"],\n",
    "        },\n",
    "    }\n",
    "\n",
    "with open(\"Llama3_70B_results.json\", \"w\") as file:\n",
    "    json.dump(llama_70b_results, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP Scores Depending on the type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Questions:\n",
      "\tLevel 0 - Average: 0.49720958333502374, Standard Deviation: 0.39090551415991964\n",
      "\tLevel 2 - Average: 0.4937701613146985, Standard Deviation: 0.39795187928994363\n",
      "\tLevel 4 - Average: 0.48152216366366646, Standard Deviation: 0.3941364925044105\n",
      "\tOverall Results - Average: 0.4908288069973935, Standard Deviation: 0.3944020534604114\n",
      "Specific Questions:\n",
      "\tLevel 0 - Average: 0.48153846815070084, Standard Deviation: 0.38203520522486284\n",
      "\tLevel 2 - Average: 0.5326249305710552, Standard Deviation: 0.35661797926999345\n",
      "\tLevel 4 - Average: 0.5344944562531858, Standard Deviation: 0.37388657064744785\n",
      "\tOverall Results - Average: 0.5165057431222898, Standard Deviation: 0.37172995489235194\n"
     ]
    }
   ],
   "source": [
    "standard_fp_scores = []\n",
    "specific_fp_scores = []\n",
    "\n",
    "for question, data in llama_70b_results.items():\n",
    "    new_row = [\n",
    "        data[\"Level 0\"][\"Level FP Score\"],\n",
    "        data[\"Level 2\"][\"Level FP Score\"],\n",
    "        data[\"Level 4\"][\"Level FP Score\"],\n",
    "    ]\n",
    "    if data[\"Type\"] == \"specific\":\n",
    "        specific_fp_scores.append(new_row)\n",
    "\n",
    "    elif data[\"Type\"] == \"standard\":\n",
    "        standard_fp_scores.append(new_row)\n",
    "\n",
    "    else:\n",
    "        # Raise error\n",
    "        raise ()\n",
    "\n",
    "standard_level_0_average, standard_level_0_std = calculate_level_avg_std(\n",
    "    0, standard_fp_scores\n",
    ")\n",
    "standard_level_2_average, standard_level_2_std = calculate_level_avg_std(\n",
    "    2, standard_fp_scores\n",
    ")\n",
    "standard_level_4_average, standard_level_4_std = calculate_level_avg_std(\n",
    "    4, standard_fp_scores\n",
    ")\n",
    "standard_overall_average, standard_overall_std = calculate_overall_avg_std(\n",
    "    standard_fp_scores\n",
    ")\n",
    "\n",
    "specific_level_0_average, specific_level_0_std = calculate_level_avg_std(\n",
    "    0, specific_fp_scores\n",
    ")\n",
    "specific_level_2_average, specific_level_2_std = calculate_level_avg_std(\n",
    "    2, specific_fp_scores\n",
    ")\n",
    "specific_level_4_average, specific_level_4_std = calculate_level_avg_std(\n",
    "    4, specific_fp_scores\n",
    ")\n",
    "specific_overall_average, specific_overall_std = calculate_overall_avg_std(\n",
    "    specific_fp_scores\n",
    ")\n",
    "\n",
    "\n",
    "print(\"Standard Questions:\")\n",
    "print(\n",
    "    f\"\\tLevel 0 - Average: {standard_level_0_average}, Standard Deviation: {standard_level_0_std}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\tLevel 2 - Average: {standard_level_2_average}, Standard Deviation: {standard_level_2_std}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\tLevel 4 - Average: {standard_level_4_average}, Standard Deviation: {standard_level_4_std}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\tOverall Results - Average: {standard_overall_average}, Standard Deviation: {standard_overall_std}\"\n",
    ")\n",
    "\n",
    "print(\"Specific Questions:\")\n",
    "print(\n",
    "    f\"\\tLevel 0 - Average: {specific_level_0_average}, Standard Deviation: {specific_level_0_std}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\tLevel 2 - Average: {specific_level_2_average}, Standard Deviation: {specific_level_2_std}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\tLevel 4 - Average: {specific_level_4_average}, Standard Deviation: {specific_level_4_std}\"\n",
    ")\n",
    "print(\n",
    "    f\"\\tOverall Results - Average: {specific_overall_average}, Standard Deviation: {specific_overall_std}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the JSON With the Overall Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_results_json = {\n",
    "    \"All Questions\": {\n",
    "        \"Overall Results\": {\n",
    "            \"Average\": f\"{overall_average}\",\n",
    "            \"Standard Dev\": f\"{overall_std}\",\n",
    "        },\n",
    "        \"Level 0\": {\n",
    "            \"Average\": f\"{level_0_average}\",\n",
    "            \"Standard Dev\": f\"{level_0_std}\",\n",
    "        },\n",
    "        \"Level 2\": {\n",
    "            \"Average\": f\"{level_2_average}\",\n",
    "            \"Standard Dev\": f\"{level_2_std}\",\n",
    "        },\n",
    "        \"Level 4\": {\n",
    "            \"Average\": f\"{level_4_average}\",\n",
    "            \"Standard Dev\": f\"{level_4_std}\",\n",
    "        },\n",
    "    },\n",
    "    \"Standard Questions\": {\n",
    "        \"Overall Results\": {\n",
    "            \"Average\": f\"{standard_overall_average}\",\n",
    "            \"Standard Dev\": f\"{standard_overall_std}\",\n",
    "        },\n",
    "        \"Level 0\": {\n",
    "            \"Average\": f\"{standard_level_0_average}\",\n",
    "            \"Standard Dev\": f\"{standard_level_0_std}\",\n",
    "        },\n",
    "        \"Level 2\": {\n",
    "            \"Average\": f\"{standard_level_2_average}\",\n",
    "            \"Standard Dev\": f\"{standard_level_2_std}\",\n",
    "        },\n",
    "        \"Level 4\": {\n",
    "            \"Average\": f\"{standard_level_4_average}\",\n",
    "            \"Standard Dev\": f\"{standard_level_4_std}\",\n",
    "        },\n",
    "    },\n",
    "    \"Specific Questions\": {\n",
    "        \"Overall Results\": {\n",
    "            \"Average\": f\"{specific_overall_average}\",\n",
    "            \"Standard Dev\": f\"{specific_overall_std}\",\n",
    "        },\n",
    "        \"Level 0\": {\n",
    "            \"Average\": f\"{specific_level_0_average}\",\n",
    "            \"Standard Dev\": f\"{specific_level_0_std}\",\n",
    "        },\n",
    "        \"Level 2\": {\n",
    "            \"Average\": f\"{specific_level_2_average}\",\n",
    "            \"Standard Dev\": f\"{specific_level_2_std}\",\n",
    "        },\n",
    "        \"Level 4\": {\n",
    "            \"Average\": f\"{specific_level_4_average}\",\n",
    "            \"Standard Dev\": f\"{specific_level_4_std}\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# Write the JSON object to a file\n",
    "with open(\"fp_overall_results.json\", \"w\") as json_file:\n",
    "    json.dump(fp_results_json, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
